{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69fd8780",
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2023-06-04T11:45:33.133431906Z",
     "start_time": "2023-06-04T11:45:33.031233103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  /home/cas /.deepface created\n",
      "Directory  /home/cas /.deepface/weights created\n",
      "data/real_and_fake_face/\n"
     ]
    }
   ],
   "source": [
    "# required packages\n",
    "#!pip install pandas\n",
    "# hoi comment\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "from deepface import DeepFace\n",
    "\n",
    "datapath = 'data/real_and_fake_face/'\n",
    "print(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e056ec85",
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2023-06-04T10:56:29.757550258Z",
     "start_time": "2023-06-04T10:56:29.727268304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of images:  2041\n",
      "real images: 1081\n",
      "fake images: 960\n",
      "easy images: 240\n",
      "mid images: 480\n",
      "hard images: 240\n"
     ]
    }
   ],
   "source": [
    "#read the file names\n",
    "# and group them by feature into a dataframe\n",
    "f_temp = []\n",
    "for path, subdirs, files in os.walk(datapath):\n",
    "    for name in files:\n",
    "        full_path = os.path.join(path, name)\n",
    "        if name.startswith('real'):\n",
    "            f_temp.append([full_path, 'real', 'real', 0, 0, 0, 0])\n",
    "        elif name.startswith('easy') or name.startswith('mid') or name.startswith('hard'):\n",
    "            split_name = name.split('_')\n",
    "            label = 'fake'\n",
    "            category = split_name[0]\n",
    "            annotation = split_name[2]\n",
    "            annotation = annotation.split('.')[0]\n",
    "            if len(annotation) == 4:\n",
    "                f_temp.append([full_path, label, category, annotation[0], annotation[1], annotation[2], annotation[3]])                \n",
    "            else:\n",
    "                print(f\"ERROR image {name}\")\n",
    "data = pd.DataFrame(f_temp, columns=['filename', 'label','category','left_eye','right_eye','nose','mouth'])\n",
    "print(\"amount of images: \", data.shape[0])\n",
    "print(f\"real images: {data[data['label']=='real'].shape[0]}\")\n",
    "print(f\"fake images: {data[data['label']=='fake'].shape[0]}\")\n",
    "print(f\"easy images: {data[data['category']=='easy'].shape[0]}\")\n",
    "print(f\"mid images: {data[data['category']=='mid'].shape[0]}\")\n",
    "print(f\"hard images: {data[data['category']=='hard'].shape[0]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2c8294",
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2023-06-04T11:51:30.014587322Z",
     "start_time": "2023-06-04T11:51:29.301242707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verified': True, 'distance': 0.21908850922038914, 'threshold': 0.4, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 146, 'y': 140, 'w': 428, 'h': 428}, 'img2': {'x': 80, 'y': 140, 'w': 436, 'h': 436}}, 'time': 0.71}\n"
     ]
    }
   ],
   "source": [
    "#verify the deepface model\n",
    "verification = DeepFace.verify(\"data/real_and_fake_face/training_real/real_00001.jpg\", \"data/real_and_fake_face/training_real/real_00002.jpg\")\n",
    "print(verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations: 100%|██████████| 960/960 [04:39<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representations stored in data/real_and_fake_face/training_fake//representations_vgg_face.pkl file.Please delete this file when you add new identities in your database.\n",
      "find function lasts  281.11802649497986  seconds\n"
     ]
    }
   ],
   "source": [
    "#find a face in a dataset\n",
    "image_real = cv.imread(\"data/real_and_fake_face/training_real/real_00002.jpg\")\n",
    "db_path = \"data/real_and_fake_face/training_fake/\"\n",
    "enforce_detection = False\n",
    "x = DeepFace.find(img_path = image_real, db_path = db_path, enforce_detection = enforce_detection)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:01:52.671843813Z",
     "start_time": "2023-06-04T11:57:11.524719066Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  6.43it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 33, 'region': {'x': 80, 'y': 140, 'w': 436, 'h': 436}, 'gender': {'Woman': 96.71955704689026, 'Man': 3.2804474234580994}, 'dominant_gender': 'Woman', 'emotion': {'angry': 0.006737637810951434, 'disgust': 1.4480664428770946e-14, 'fear': 99.99027252313226, 'happy': 0.0005937521311131792, 'sad': 0.0018653215697746156, 'surprise': 7.018928458833224e-05, 'neutral': 0.00045881828542566807}, 'dominant_emotion': 'fear', 'race': {'asian': 24.265503970920566, 'indian': 6.425423154184442, 'black': 2.348557020895836, 'white': 34.15506074964276, 'middle eastern': 11.184428044029707, 'latino hispanic': 21.62102054106944}, 'dominant_race': 'white'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#analyze face for features\n",
    "features = ['age','gender','emotion','race']\n",
    "x = DeepFace.analyze(\"data/real_and_fake_face/training_real/real_00002.jpg\", actions = features)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:27:12.096756670Z",
     "start_time": "2023-06-04T12:27:11.377011619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
